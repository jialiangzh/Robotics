<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <title>Robotic Pet</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>Robotic Pet</h1>
        <h2>EE 125 Final Project</h2>

        <section id="downloads">
          <a href="https://github.com/jialiangzh/Robotics/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/jialiangzh/Robotics/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/jialiangzh/Robotics" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
	  
<h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Welcome to Our Robotic Pet Project!</h3>

<h3>	
<a id="Robotic Pet" class="anchor" href="#Robotic Pet" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Robotic Pet</h3>
	
<div>
<img src="./images/IMG_3686.JPG" alt="RoboticPet" height="400" align="middle">
</div>

<p>
The Robotic Pet is an automated robot that can mimic common pets behaviours, like entertaining with
a ball autonomously and interacting with human gesture interactively. As the final project of EE 125 
Introduction to Robotics class, the robotic pet is built on the UC Berkeley TETRIX robot platform.
</p>

<h3>	
<a id="Introduction" class="anchor" href="#Introduction" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Introduction</h3>

<p>
Our project aims to bring convenience and entertainment to people's everyday life.
An ideal robotic pet can follow the master like a servant and can perform real time communication 
with the master. The robotic pet should also resemble a real pet and bring enjoyment to master's 
free time. In our project, we specifically investigate on implementing two major functionalities 
for our robot pet: hand gesture tracking and self entertaining with a ball. We want it to be live!
</p>

<!-- <pre><code>$ cd your_repo_root/repo_name
$ git fetch origin
$ git checkout gh-pages
</code></pre> -->

<!-- <p>If you're using the GitHub for Mac, simply sync your repository 
and you'll see the new branch.</p> -->

<h3>
<a id="Design" class="anchor" href="#Design" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Design</h3>

<h4>
<a id="Computer-Vision" class="anchor" href="#Computer-Vision" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Computer Vision</h4>

<p>
a) Data streaming: Because the board on the robot does not have enough calculating power, we decide to put all heavy computations on our
laptop. So the first task is to stream the data from the robot camera to our laptop. The package "raspicam_node" really helped us on adjusting
framerate and quality of the image so that the laptop can receive the data stream in real time.
</p>

<p>
b) Our second task is to do camera calibration. By computing the homography matrix H, we are able to map the 2-dimensional pixel position
 of the digital camera into the actual floor coordinate (x, y). The robot now can process the object position in the ground coordinates.
</p>

<div>
<img src="./images/Calibration_Graph.jpg" alt="Calibration_Graph" height="250" align="middle">
</div>

<p>
c) Now we can visualize the ball and the hand. This is done by filtering out the environment pixels and using the python cv 
functions to process the target countours and to locate the center of the target. If other environment noise is present, we should
find the largest bounding box for the countours and to indicate the location. If the largest contour is small enough, then we can say
the target is not present in our image. The lab6 "Object tracking" gives us the initial help. We build upon the lab6, designed seperate mode
 for the human hand and the ball, implemented the bounding box area criterian for checking the presence of the object, and designed the 
approprate paramemters for the Kalman filter for the linear motion prediction. Using ROS publisher, predicted location and the actual location
 of target object is published and wating for further processing.
</p>

<h4>
<a id="Control-Signal-Generation" class="anchor" href="#Control-Signal-Generation" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Control Signal Generation</h4>

<p>
a) For the ball: Our goal is to let the robot pet play the ball by itself. When the image processing publisher tells us there is no object
present, we should let the pet rotate to find the ball until the ball come into its vision. Then, using feedback control, the pet adjusts its
angle until it faces directly to the ball. Then by several short forward movement, it further adjusts its angle. Finally, it accelerate with
full speed and run into the ball. The ball is then kicked away and the robot search again and repeat the process. Our controller code does this
job and publishes velocity control signal remotely to our robot.
</p>

<p>
b) For the human hand: The pet should be able to get of the hand position and keep a certain distance with the hand. When the hand is
When the hand is far away, it should be able to catch up with the hand; and when the hand is shaking left or right, the pet should rotate and
keep track of the hand position.
</p>

<h4>
<a id="Materializing-Velocity-Signal" class="anchor" href="#Materializing-Velocity-Signal" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Materializing Velocity Signal</h4>

<p>
With the I2C tool, we are able feed the speed information from the raspberry pi board to the servo motor. On our raspberry pi board, we 
subscribe the velocity command from the ROS master, and send binary signal to the predetermined pins on our board. Finally the electric signal
will be received by the left and the right motor and the motor will perform as desired.
</p>

<h3>
<a id="Implementation" class="anchor" href="#Implementation" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Implementation</h3>
	
<h4>
<a id="DesignCriteria" class="anchor" href="#DesignCriteria" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Design Criteria</h4>
	
<ul>
<li>1</li>
<li>2</li>
<li>3</li>
</ul>

<h4>
<a id="Functionality" class="anchor" href="#Functionality" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Functionality</h4>
	
<ul>
<li>Self entertaining with a ball</li>
<li>Human master's following</li>
<li>Human master's hand gesture comprehension</li>
</ul>
	
<h4>
<a id="Hardware" class="anchor" href="#Hardware" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Hardware</h4>

<p>
Raspberry Pi with camera, 
rPi extension board, 
Tetrix Robot frames and wheels, 
Tetrix DC motor and 12V Battery
</p>

<h4>
<a id="Software" class="anchor" href="#Software" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Software</h4>

<p>
ROS Hydro & Groovy, 
Debian Weezy
</p>

<h4>
<a id="FlowChart" class="anchor" href="#FlowChart" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Flow Chart</h4>
	
<p>For Self-entertaining with the ball:</p>

<div>
<img src="./images/Entertaining_Ball.jpg" alt="Entertaining_Ball" height="250" align="middle">
</div>

<p>For human hand gesture comprehension:</p>

<div>
<img src="./images/Gesture_Comprehension.jpg" alt="Gesture_Comprehension" height="250" align="middle">
</div>
	
<h3>
<a id="Conclusion" class="anchor" href="#Conclusion" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>Conclusion</h3>
	
<p>
Our project was quite successful, in consistant with our project goals and designs.
</p>

<!-- <p>If you prefer to not use the automatic generator, push a branch named 
<code>gh-pages</code> to your repository to create a page manually. 
In addition to supporting regular HTML content, GitHub Pages support Jekyll, 
a simple, blog aware static site generator written by our own Tom Preston-Werner. 
Jekyll makes it easy to create site-wide headers and footers without having to copy 
them across every page. It also offers intelligent blog support and other advanced 
templating features.</p> -->

<h3>
<a id="Team" class="anchor" href="#Team" aria-hidden="true"><span class="octicon octicon-link">
	</span></a>Team</h3>
	
<h4>
<a name="Xingchun-Wang" class="anchor" href="#Xingchun-Wang">
	<span class="octicon octicon-link"></span></a>Xingchun Wang</h4>

<div>
<img src="./images/Gesture_Comprehension.jpg" alt="Xingchun" height="200" align="middle">
</div>

<p>
I am a third year Electrical Engineering &amp; Computer Science student at UC Berkeley.
I like to playing piano and playing video games. This is an enjoyable introductory class
on robotics and it's very exciting to see the robot works out after days and nights of debugging.
I have learnt a lot here on both the theory and the applications. You can contact me 
by shooting me an <a href="acjwxc@126.com">email</a>.</p>

<h4>
<a name="Jialiang-Zhang" class="anchor" href="#Jialiang-Zhang">
	<span class="octicon octicon-link"></span></a>Jialiang Zhang</h4>

<div>
<img src="./images/Gesture_Comprehension.jpg" alt="Jialiang" height="200" align="middle">
</div>

<p>
I am a master student in Electrical Engineering &amp; Computer Science at UC Berkeley. 
My interest include .... 
I got involved in this class because of previous internships with robotic control 
(Disney Imagineering and Universal Creative). I also have fond memories of high school 
robotics competitions. If you would like to know more about me check out my 
<a href="http://www.linkedin.com/...">LinkedIn</a> or shoot me an 
<a href="mailto:@berkeley.edu">email!</a></p>

<!-- <p>You can <a href="https://github.com/blog/821" class="user-mention">@mention</a> 
a GitHub username to generate a link to their profile. The resulting <code>&lt;a&gt;</code> 
element will link to the contributor's GitHub Profile. For example: 
In 2007, Chris Wanstrath (<a href="https://github.com/defunkt" class="user-mention">@defunkt</a>), 
PJ Hyett (<a href="https://github.com/pjhyett" class="user-mention">@pjhyett</a>), 
and Tom Preston-Werner (<a href="https://github.com/mojombo" class="user-mention">@mojombo</a>) 
founded GitHub.</p> -->

<h3>
<a id="References" class="anchor" href="#References" aria-hidden="true">
	<span class="octicon octicon-link"></span></a>References</h3>
	
<p>
• Department of Electrical Engineering and Computer Sciences. 
Austin Buchan and Aaron Bestick. EE C125: Introduction to Robotics Lab Menu. 
University of California, Berkeley. 2014.
</p>

<!-- <p>Having trouble with Pages? Check out the documentation 
at <a href="https://help.github.com/pages">https://help.github.com/pages</a> 
or contact <a href="mailto:support@github.com">support@github.com</a> 
and we’ll help you sort it out.</p> -->
      </section>
    </div>
    
  </body>
</html>
